{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 00:19:21.272716: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-29 00:19:21.329800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-29 00:19:21.329847: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-29 00:19:21.332439: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-29 00:19:21.350225: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-29 00:19:21.941750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):# permite que cada token en una secuencia atienda a cada otro token en la misma secuencia\n",
    "    def __init__(self, embed_dim, num_heads=8):#Bloques de 8 en 8 tokens\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim#dimensiones del emmbeding\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "            \n",
    "        self.projection_dim = embed_dim // num_heads#Proyeccion de cada cabeza\n",
    "        #Capas densas para query, key y value\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):#q informacion en entrada, k busca relevancia, v informacion a recuperar\n",
    "        score = tf.matmul(query, key, transpose_b=True)#Producto punto entre query y key\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)#escalado de la raiz de key\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)#Aplicacion de softmax para los pesos de atención\n",
    "        output = tf.matmul(weights, value)#Producto punto entre los pesos y el valor\n",
    "        \n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):#x tensor de entrada, \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))#Separa  las attention head\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])#traspone las dimensiones a un orden adecuado\n",
    "\n",
    "    def call(self, inputs):#Llamada al modelo\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)#obtenemos query key y value mediante las capas densas\n",
    "        key = self.key_dense(inputs)#mediante proyección\n",
    "        value = self.value_dense(inputs)\n",
    "        \n",
    "        query = self.separate_heads(query, batch_size)#Separar query key value en diferentes cabezas\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "        \n",
    "        attention, weights = self.attention(query, key, value)#Calculamos la atencion escalada\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])#Reorganizamos el tensor\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):#Bloque transformer con capa feed forward\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = tf.keras.Sequential(#Capa feed\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)#Capas de normalización\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)#Desactiva neuronas al azar para prevenir overfitting\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)#Multi head attenrion\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)#add &norm1\n",
    "        ffn_output = self.ffn(out1)#Feed forward\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)#add &norm 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):#embedding de tokens y de posicion\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)#tokens unicos en el conjunto\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)#Maximo de secuencias de entrada\n",
    "                                                                                #emb dim dimension de embeddings\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]#Longitud de secuencia de entrada dinamica\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)#Posiciones de los tokens\n",
    "        positions = self.pos_emb(positions)#Mapeo de posiciones\n",
    "        x = self.token_emb(x)#mapea los tokens a su embedding\n",
    "        return x + positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(tf.keras.Model):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, num_heads, ff_dim, num_blocks):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)#Positional embedding layer\n",
    "        self.transformer_blocks = [TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_blocks)]#Bloques transformer\n",
    "        self.dense_layer = Dense(vocab_size, activation=\"softmax\")  # capa final\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding_layer(inputs)#Se obtienen el mapeo de tokens mas sus posiciones\n",
    "        for transformer_block in self.transformer_blocks:#Iteracion en bloques de transformer\n",
    "            x = transformer_block(x)#Se transforman las entradas en cada iteracion de los bloques\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        return self.dense_layer(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso:\n",
    "maxlen = 100  # Longitud máxima de la secuencia de entrada\n",
    "vocab_size = 20000  # Tamaño del vocabulario\n",
    "embed_dim = 128  # Dimensión de las embeddings\n",
    "num_heads = 8  # Número de cabezas en la atención\n",
    "ff_dim = 512  # Dimensión de la capa feed-forward interna\n",
    "num_blocks = 4  # Número de bloques del transformador\n",
    "\n",
    "model = TransformerModel(maxlen, vocab_size, embed_dim, num_heads, ff_dim, num_blocks)\n",
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_and_position_embeddi  multiple                  2572800   \n",
      " ng_6 (TokenAndPositionEmbe                                      \n",
      " dding)                                                          \n",
      "                                                                 \n",
      " transformer_block_24 (Tran  multiple                  198272    \n",
      " sformerBlock)                                                   \n",
      "                                                                 \n",
      " transformer_block_25 (Tran  multiple                  198272    \n",
      " sformerBlock)                                                   \n",
      "                                                                 \n",
      " transformer_block_26 (Tran  multiple                  198272    \n",
      " sformerBlock)                                                   \n",
      "                                                                 \n",
      " transformer_block_27 (Tran  multiple                  198272    \n",
      " sformerBlock)                                                   \n",
      "                                                                 \n",
      " dense_174 (Dense)           multiple                  129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3366017 (12.84 MB)\n",
      "Trainable params: 3366017 (12.84 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "model.build(input_shape=(None, maxlen))\n",
    "file='transformer_model'\n",
    "plot_model(model,to_file=file+'.png',show_shapes=True,show_dtype=False)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de ejemplo\n",
    "import numpy as np\n",
    "x_train = np.random.randint(0, vocab_size, size=(1000, maxlen))\n",
    "y_train = np.random.randint(0, 2, size=(1000, 1))\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
